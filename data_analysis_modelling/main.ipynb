{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, PolynomialFeatures, LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "aug_data = pd.read_json('../data/aug.json', convert_dates=True)\n",
    "sep_data = pd.read_json('../data/sept.json', convert_dates=True)\n",
    "oct_data = pd.read_json('../data/oct.json', convert_dates=True)\n",
    "nov_data = pd.read_json('../data/nov.json', convert_dates=True)\n",
    "\n",
    "rec_data = pd.read_json('../data/mod_recovery_data.json', convert_dates=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123 entries, 0 to 122\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   facility      123 non-null    object        \n",
      " 1   date          123 non-null    datetime64[ns]\n",
      " 2   timeStart     123 non-null    object        \n",
      " 3   timeEnd       123 non-null    object        \n",
      " 4   supplierCode  123 non-null    object        \n",
      " 5   suppliedM3    123 non-null    float64       \n",
      " 6   recoveredM3   123 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(2), object(4)\n",
      "memory usage: 6.9+ KB\n"
     ]
    }
   ],
   "source": [
    "aug_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processTime missing from aug_data dataset\n",
      "supplier missing from aug_data dataset\n",
      "\n",
      "\n",
      "processTime missing from aug_data dataset\n",
      "supplier missing from aug_data dataset\n",
      "\n",
      "\n",
      "processTime missing from aug_data dataset\n",
      "supplier missing from aug_data dataset\n",
      "\n",
      "\n",
      "timeStart missing from aug_data dataset\n",
      "processTime missing from aug_data dataset\n",
      "suppliedM3 missing from aug_data dataset\n",
      "recoveredM3 missing from aug_data dataset\n",
      "timeEnd missing from aug_data dataset\n",
      "supplierCode missing from aug_data dataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for feat in sep_data.columns.to_list():\n",
    "    if feat not in aug_data.columns.to_list():\n",
    "        print(f'{feat} missing from aug_data dataset')\n",
    "print('\\n')\n",
    "\n",
    "for feat in oct_data.columns.to_list():\n",
    "    if feat not in aug_data.columns.to_list():\n",
    "        print(f'{feat} missing from aug_data dataset')\n",
    "print('\\n')\n",
    "\n",
    "for feat in nov_data.columns.to_list():\n",
    "    if feat not in aug_data.columns.to_list():\n",
    "        print(f'{feat} missing from aug_data dataset')\n",
    "\n",
    "print('\\n')\n",
    "for feat in sep_data.columns.to_list():\n",
    "    if feat not in rec_data.columns.to_list():\n",
    "        print(f'{feat} missing from aug_data dataset')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "suppliedM3, recoveredM3 are missing from rec_data where it is present volumeM3, i assume that volume consist in the volume of recoveredM3 hence is the same.. probably will be useful to investigate distributions.\n",
    "\n",
    "timeStart and timeEnd are missing from rec_data, it is present a time feature, however i dont know to what is related.\n",
    "\n",
    "is missing also the processTime and suplierCode, since the supplierCode is possible to recover from before datasets process time i have no idea how to find it at this moment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 123 entries, 0 to 122\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   facility      123 non-null    object        \n",
      " 1   date          123 non-null    datetime64[ns]\n",
      " 2   timeStart     123 non-null    object        \n",
      " 3   timeEnd       123 non-null    object        \n",
      " 4   supplierCode  123 non-null    object        \n",
      " 5   suppliedM3    123 non-null    float64       \n",
      " 6   recoveredM3   123 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(2), object(4)\n",
      "memory usage: 6.9+ KB\n"
     ]
    }
   ],
   "source": [
    "aug_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 232 entries, 0 to 231\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   facility      232 non-null    object        \n",
      " 1   timeStart     232 non-null    object        \n",
      " 2   processTime   111 non-null    object        \n",
      " 3   supplier      111 non-null    object        \n",
      " 4   suppliedM3    232 non-null    float64       \n",
      " 5   recoveredM3   232 non-null    float64       \n",
      " 6   date          121 non-null    datetime64[ns]\n",
      " 7   timeEnd       121 non-null    object        \n",
      " 8   supplierCode  121 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(6)\n",
      "memory usage: 16.4+ KB\n"
     ]
    }
   ],
   "source": [
    "sep_data.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "facility          2\ntimeStart       220\nprocessTime      38\nsupplier          4\nsuppliedM3      120\nrecoveredM3     129\ndate             29\ntimeEnd         107\nsupplierCode      3\ndtype: int64"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_data.nunique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "all_ds = pd.concat([aug_data, sep_data, oct_data, nov_data])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 329 entries, 0 to 226\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   facility      329 non-null    object        \n",
      " 1   date          0 non-null      datetime64[ns]\n",
      " 2   timeStart     329 non-null    object        \n",
      " 3   timeEnd       0 non-null      object        \n",
      " 4   supplierCode  0 non-null      object        \n",
      " 5   suppliedM3    329 non-null    float64       \n",
      " 6   recoveredM3   329 non-null    float64       \n",
      " 7   processTime   329 non-null    object        \n",
      " 8   supplier      329 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(6)\n",
      "memory usage: 25.7+ KB\n"
     ]
    }
   ],
   "source": [
    "ptds = all_ds[~all_ds.processTime.isna()]\n",
    "ptds.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 481 entries, 0 to 227\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   facility      481 non-null    object        \n",
      " 1   date          481 non-null    datetime64[ns]\n",
      " 2   timeStart     481 non-null    object        \n",
      " 3   timeEnd       481 non-null    object        \n",
      " 4   supplierCode  481 non-null    object        \n",
      " 5   suppliedM3    481 non-null    float64       \n",
      " 6   recoveredM3   481 non-null    float64       \n",
      " 7   processTime   0 non-null      object        \n",
      " 8   supplier      0 non-null      object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(6)\n",
      "memory usage: 37.6+ KB\n"
     ]
    }
   ],
   "source": [
    "ptds = all_ds[~all_ds.timeEnd.isna()]\n",
    "ptds.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "# pd.to_datetime(ptds.timeEnd, format='%I:%M:%S %p')\n",
    "def convert_to_hours(delta):\n",
    "    total_seconds = delta.total_seconds()\n",
    "    hours = str(int(total_seconds // 3600)).zfill(2)\n",
    "    minutes = str(int((total_seconds % 3600) // 60)).zfill(2)\n",
    "    return f\"{hours}:{minutes}\"\n",
    "\n",
    "all_ds['processTime'] = all_ds.apply(lambda x: convert_to_hours((pd.to_datetime(x.timeEnd, format='%I:%M:%S %p') - pd.to_datetime(x.timeStart, format='%I:%M:%S %p'))) if pd.isna(x.processTime) else x.processTime , axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "array([nan, 'Mary', 'Mary Therese', 'Mary Jane', 'Mary Anne'],\n      dtype=object)"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ds.supplier.unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "all_ds['supplier_id'] = all_ds.apply(lambda x: x.supplierCode if pd.isna(x.supplier) else x.supplier, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 810 entries, 0 to 227\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   facility      810 non-null    object        \n",
      " 1   date          481 non-null    datetime64[ns]\n",
      " 2   timeStart     810 non-null    object        \n",
      " 3   timeEnd       481 non-null    object        \n",
      " 4   supplierCode  481 non-null    object        \n",
      " 5   suppliedM3    810 non-null    float64       \n",
      " 6   recoveredM3   810 non-null    float64       \n",
      " 7   processTime   810 non-null    object        \n",
      " 8   supplier      329 non-null    object        \n",
      " 9   supplier_id   810 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(7)\n",
      "memory usage: 69.6+ KB\n"
     ]
    }
   ],
   "source": [
    "all_ds.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "not all dates are filled, however it is possibile to  see that those that are absent have the full date in the timeStart.\n",
    "hence i can easily fill the gaps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "all_ds['date'] = all_ds.apply(lambda x: pd.to_datetime(x.timeStart).date() if pd.isna(x.date) else pd.to_datetime(x.date).date() , axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 810 entries, 0 to 227\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   facility      810 non-null    object \n",
      " 1   date          810 non-null    object \n",
      " 2   timeStart     810 non-null    object \n",
      " 3   timeEnd       481 non-null    object \n",
      " 4   supplierCode  481 non-null    object \n",
      " 5   suppliedM3    810 non-null    float64\n",
      " 6   recoveredM3   810 non-null    float64\n",
      " 7   processTime   810 non-null    object \n",
      " 8   supplier      329 non-null    object \n",
      " 9   supplier_id   810 non-null    object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 69.6+ KB\n"
     ]
    }
   ],
   "source": [
    "all_ds.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "all_ds.drop(columns=[ 'supplierCode', 'supplier'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 810 entries, 0 to 227\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   facility     810 non-null    object \n",
      " 1   date         810 non-null    object \n",
      " 2   timeStart    810 non-null    object \n",
      " 3   timeEnd      481 non-null    object \n",
      " 4   suppliedM3   810 non-null    float64\n",
      " 5   recoveredM3  810 non-null    float64\n",
      " 6   processTime  810 non-null    object \n",
      " 7   supplier_id  810 non-null    object \n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 57.0+ KB\n"
     ]
    }
   ],
   "source": [
    "all_ds.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "facility         2\ndate           120\ntimeStart      614\ntimeEnd        325\nsuppliedM3     199\nrecoveredM3    213\nprocessTime    233\nsupplier_id      7\ndtype: int64"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ds.nunique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'll make some training and predictions on the past data with both one hot hencoding and label encoding in order to see if the features will have make tangible differences."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "ds_dummies = pd.get_dummies(all_ds, columns=['facility', 'supplier_id'])\n",
    "\n",
    "ds_dummies.drop(columns=['timeStart', 'timeEnd'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "ds_dummies['processTime'] = ds_dummies[ 'processTime'] + ':00'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "ds_dummies['processTime'] = ds_dummies.apply(lambda x: pd.Timedelta(x.processTime)/pd.Timedelta(minutes=60), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "ds_dummies.drop(columns=['date'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "x = ds_dummies.drop(columns=['recoveredM3'])\n",
    "y = ds_dummies['recoveredM3']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "degree = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "models = [LinearRegression(),\n",
    "          Ridge(random_state=42),\n",
    "          MLPRegressor(hidden_layer_sizes=(10,), random_state=42, max_iter=10000),\n",
    "          SVR(gamma='scale'),\n",
    "          RandomForestRegressor(n_estimators=300)\n",
    "          ]\n",
    "\n",
    "names = [\n",
    "        'linreg',\n",
    "        'ridge',\n",
    "        'mlp',\n",
    "        'svr',\n",
    "        'rf'\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------------+--------------------+\n",
      "|      model       |         MSE         |         R2         |\n",
      "+------------------+---------------------+--------------------+\n",
      "|      linreg      | 0.11170385253720046 | 0.8720620164662826 |\n",
      "|      ridge       | 0.11010811602252846 | 0.8738896643701027 |\n",
      "|       mlp        | 0.17177785449937077 | 0.8032573468038724 |\n",
      "|       svr        | 0.11516316516789216 | 0.8680999554242426 |\n",
      "|        rf        | 0.13387013485128277 | 0.8466742666502378 |\n",
      "| sin+poly2+linreg | 0.12056584623078706 | 0.8619120925604047 |\n",
      "| sin+poly2+ridge  | 0.12137536851207002 | 0.8609849208833269 |\n",
      "+------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "t = PrettyTable()\n",
    "t.field_names = ['model', 'MSE', 'R2']\n",
    "\n",
    "for model, name in zip(models, names):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.8, random_state=42, shuffle=True)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_hat = model.predict(x_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_hat)\n",
    "    r2 = r2_score(y_test, y_hat)\n",
    "    t.add_row([name, mse, r2])\n",
    "\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "with the data i have the models are working kinda well"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "(array(['har', 'dic', 'tom', 'Mary', 'Mary Therese', 'Mary Jane',\n        'Mary Anne'], dtype=object),\n array(['Newcastle', 'Bundaberg'], dtype=object))"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ds.supplier_id.unique(), all_ds.facility.unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "all_ds.supplier_id = labelencoder.fit_transform(all_ds.supplier_id)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "all_ds.facility = labelencoder.fit_transform(all_ds.facility)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-174-77197d6d7828>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label_encoded_ds['processTime'] = label_encoded_ds[ 'processTime'] + ':00'\n",
      "<ipython-input-174-77197d6d7828>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label_encoded_ds['processTime'] = label_encoded_ds.apply(lambda x: pd.Timedelta(x.processTime)/pd.Timedelta(minutes=60), axis=1)\n"
     ]
    }
   ],
   "source": [
    "label_encoded_ds = all_ds[['facility', 'suppliedM3', 'recoveredM3', 'processTime', 'supplier_id']]\n",
    "\n",
    "label_encoded_ds['processTime'] = label_encoded_ds[ 'processTime'] + ':00'\n",
    "label_encoded_ds['processTime'] = label_encoded_ds.apply(lambda x: pd.Timedelta(x.processTime)/pd.Timedelta(minutes=60), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "# creating some base models in order to understand how those data would be usefull to predict and if prediction might be good\n",
    "\n",
    "x = label_encoded_ds.drop(columns=['recoveredM3'])\n",
    "y = label_encoded_ds['recoveredM3']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------------+---------------------+\n",
      "|      model       |         MSE         |          R2         |\n",
      "+------------------+---------------------+---------------------+\n",
      "|      linreg      | 0.11320081065711592 |  0.8703475026071242 |\n",
      "|      ridge       |  0.1127020910309505 |  0.8709187020946176 |\n",
      "|       mlp        | 0.13584958419421003 |  0.8444071402110945 |\n",
      "|       svr        | 0.11563866614389448 |  0.8675553489970131 |\n",
      "|        rf        | 0.13517859755375033 |  0.8451756426020921 |\n",
      "| sin+poly2+linreg |  0.8486608522420392 | 0.02800166982876562 |\n",
      "| sin+poly2+ridge  |  0.8489494092324974 | 0.02767117630812832 |\n",
      "+------------------+---------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "t = PrettyTable()\n",
    "t.field_names = ['model', 'MSE', 'R2']\n",
    "\n",
    "\n",
    "for model, name in zip(models, names):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.8, random_state=42, shuffle=True)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_hat = model.predict(x_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_hat)\n",
    "    r2 = r2_score(y_test, y_hat)\n",
    "    t.add_row([name, mse, r2])\n",
    "\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "all_ds.drop(columns=['date'], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "all_ds['processTime'] = ds_dummies['processTime']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "all_ds['mean'] = all_ds.groupby(by=['facility', 'supplier_id'])['processTime'].transform('mean')\n",
    "all_ds['mean_by_facility'] = all_ds.groupby(by=['facility'])['processTime'].transform('mean')\n",
    "all_ds['mean_by_supplier'] = all_ds.groupby(by=['supplier_id'])['processTime'].transform('mean')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "after loking at the recovery data to predict it is possible to see that there are no endTime feature hence it is not possible to have the information of the processTime, we can estimate an average processTime by facility and supplier, add these info to the data and see how the model works."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "# all_ds['timeStart'] = all_ds.apply(lambda x: pd.Timedelta(x.timeStart)/pd.Timedelta(minutes=60), axis=1)\n",
    "ds_avg = all_ds[['facility', 'suppliedM3', 'supplier_id', 'recoveredM3', 'mean_by_supplier', 'mean_by_facility']]\n",
    "\n",
    "x = ds_avg.drop(columns=['recoveredM3'])\n",
    "y = ds_avg['recoveredM3']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------------+----------------------+\n",
      "|      model       |         MSE         |          R2          |\n",
      "+------------------+---------------------+----------------------+\n",
      "|      linreg      | 0.11628988199371496 |  0.8696836699837165  |\n",
      "|      ridge       | 0.11403074139625034 |  0.8722152996199758  |\n",
      "|       mlp        | 0.10756495408571742 |  0.879460965868223   |\n",
      "|       svr        | 0.11292757295911378 |  0.8734515280833017  |\n",
      "|        rf        | 0.14370566866792048 |  0.8389610942734335  |\n",
      "| sin+poly2+linreg |   0.86451764269782  | 0.031207492008656024 |\n",
      "| sin+poly2+ridge  |  0.8645839054018672 | 0.031133236946561782 |\n",
      "+------------------+---------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "t = PrettyTable()\n",
    "t.field_names = ['model', 'MSE', 'R2']\n",
    "\n",
    "\n",
    "for model, name in zip(models, names):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.6, random_state=42, shuffle=True)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_hat = model.predict(x_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_hat)\n",
    "    r2 = r2_score(y_test, y_hat)\n",
    "    t.add_row([name, mse, r2])\n",
    "\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "with the new feature created we can see that the MLPregressor works best, hence i decide to use that model to predict the recovered volumes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now i'll prepare the data for the prediction, in order to have same structure and data with the trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "rec_data['facility'] = labelencoder.fit_transform(rec_data.facility)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "rec_data.drop(columns=['date', 'time'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "data": {
      "text/plain": "     facility  supplier_id      mean\n0           1            5  0.887957\n1           1            4  2.654192\n2           1            5  0.887957\n3           1            6  1.836708\n4           1            4  2.654192\n..        ...          ...       ...\n223         0            1  1.318182\n224         0            0  2.425556\n225         1            6  1.836708\n226         0            3  1.830616\n227         1            6  1.836708\n\n[810 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facility</th>\n      <th>supplier_id</th>\n      <th>mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.887957</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>4</td>\n      <td>2.654192</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.887957</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>6</td>\n      <td>1.836708</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>4</td>\n      <td>2.654192</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>223</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1.318182</td>\n    </tr>\n    <tr>\n      <th>224</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2.425556</td>\n    </tr>\n    <tr>\n      <th>225</th>\n      <td>1</td>\n      <td>6</td>\n      <td>1.836708</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1.830616</td>\n    </tr>\n    <tr>\n      <th>227</th>\n      <td>1</td>\n      <td>6</td>\n      <td>1.836708</td>\n    </tr>\n  </tbody>\n</table>\n<p>810 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_ds[['facility', 'supplier_id', 'mean']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "rc = rec_data.copy()\n",
    "rc['supplier'] = labelencoder.fit_transform(rc.supplier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "with the average process time found before by facility and suplier i add them to the data that has to be used for the prediction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-186-53742cd76f50>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tomgds.drop_duplicates(inplace=True)\n",
      "<ipython-input-186-53742cd76f50>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tomgds.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "tomgds = all_ds[['facility', 'mean_by_facility']]\n",
    "\n",
    "tomgds.columns = ['facility', 'mean_by_facility']\n",
    "tomgds.drop_duplicates(inplace=True)\n",
    "rec = pd.merge(rc, tomgds, how='left',  on=['facility'])\n",
    "\n",
    "tomgds = all_ds[['supplier_id', 'mean_by_supplier']]\n",
    "\n",
    "tomgds.columns = ['supplier', 'mean_by_supplier']\n",
    "tomgds.drop_duplicates(inplace=True)\n",
    "rec = pd.merge(rec, tomgds, how='left',  on=['supplier'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "ml = MLPRegressor(hidden_layer_sizes=(90,), random_state=53, max_iter=10000)\n",
    "\n",
    "ml.fit(x, y)\n",
    "\n",
    "rec_data['predicted'] = ml.predict(rec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "rec_data.to_csv('predicted_recovered')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
